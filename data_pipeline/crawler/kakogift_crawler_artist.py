# -*- coding: utf-8 -*-
import os
import re
import time
from urllib.parse import urljoin

import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

from base_crawler import BaseCrawler


class KakaoGiftArtistCrawler(BaseCrawler):
    """
    ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„° ì¹´í…Œê³ ë¦¬ ì „ìš© í¬ë¡¤ëŸ¬
    - ìƒìœ„ ì¹´í…Œê³ ë¦¬: ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°
    - í•˜ìœ„ ì¹´í…Œê³ ë¦¬: ìŠ¤íƒ€ì•¨ë²”, ì• ë‹ˆë©”ì´ì…˜ ìºë¦­í„°, ì¸ë””ì‘ê°€, ì• ë‹ˆë©€ìºë¦­í„°, ì›¹ì†Œì„¤, ê²Œì„
    - íë¦„: ìƒìœ„ ì¹´í…Œê³ ë¦¬ â†’ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ â†’ ì „ì²´ íƒ­ â†’ ì¹´ë“œ ëª©ë¡ ìˆ˜ì§‘
    - ì¹´ë“œ í•„ë“œ: brand, product_name, price, satisfaction_pct, review_count,
                wish_count, tags, product_url
    """

    BASE = "https://gift.kakao.com"
    DEFAULT_START = "https://gift.kakao.com/home?categoryLayer=OPEN"

    # ë™ì‘ íŒŒë¼ë¯¸í„°
    SCROLL_PAUSE = 0.8
    CLICK_PAUSE = 0.5
    MAX_SCROLL_TRIES = 100  # 300ê°œê°€ ëª¨ì¼ ë•Œê¹Œì§€ ì¶©ë¶„íˆ ìŠ¤í¬ë¡¤
    IMPLICIT_WAIT = 5

    # ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„° í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ëª©ë¡
    ARTIST_SUBCATEGORIES = [
        "ìŠ¤íƒ€ì•¨ë²”",
        "ì• ë‹ˆë©”ì´ì…˜ ìºë¦­í„°", 
        "ì¸ë””ì‘ê°€",
        "ì• ë‹ˆë©€ìºë¦­í„°",
        "ì›¹ì†Œì„¤",
        "ê²Œì„"
    ]

    def __init__(
        self,
        output_dir: str,
        *,
        output_filename: str = "kakao_gifts_artist.csv",
        headless: bool = False,
        items_per_subcat: int = 300,
        start_url: str | None = None,
    ):
        super().__init__(output_dir=output_dir)
        self.output_path = os.path.join(output_dir, output_filename)

        self.headless = headless
        self.items_per_subcat = items_per_subcat
        self.start_url = start_url or self.DEFAULT_START

        self.driver = None
        self.all_rows = []

    # -------------------- 1) ë¸Œë¼ìš°ì € --------------------
    def start_browser(self):
        opts = Options()
        if self.headless:
            opts.add_argument("--headless=new")
        opts.add_argument("--window-size=1500,1100")
        opts.add_argument("--no-sandbox")
        opts.add_argument("--disable-gpu")
        opts.add_argument("--lang=ko-KR")
        opts.add_argument("--disable-dev-shm-usage")
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=opts)
        self.driver.implicitly_wait(self.IMPLICIT_WAIT)

    # -------------------- ìœ í‹¸ --------------------
    def wait(self, t=None):
        time.sleep(t if t is not None else self.SCROLL_PAUSE)

    def js_click(self, el):
        try:
            self.driver.execute_script("arguments[0].click();", el)
        except WebDriverException:
            try:
                el.click()
            except Exception:
                pass
        self.wait(self.CLICK_PAUSE)

    def safe_text(self, el):
        try:
            return el.text.strip()
        except Exception:
            return ""

    def to_int(self, text):
        if not text:
            return None
        try:
            return int(re.sub(r"[^\d]", "", text))
        except ValueError:
            return None

    # -------------------- ì¹´í…Œê³ ë¦¬ ë„¤ë¹„ê²Œì´ì…˜ --------------------
    def ensure_category_panel(self):
        """ì¹´í…Œê³ ë¦¬ íŒ¨ë„ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì•ˆ ì—´ë ¤ìˆìœ¼ë©´ ì—´ê¸°"""
        try:
            # ì´ë¯¸ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
            panel = self.driver.find_element(By.CSS_SELECTOR, ".category_layer")
            if panel.is_displayed():
                return True
        except NoSuchElementException:
            pass
        
        # íŒ¨ë„ ì—´ê¸° ì‹œë„
        try:
            menu_btn = self.driver.find_element(By.CSS_SELECTOR, ".btn_menu, .link_menu, .btn_category")
            self.js_click(menu_btn)
            self.wait(1.0)
            return True
        except NoSuchElementException:
            # URLì— categoryLayer=OPENì´ ìˆìœ¼ë©´ ì´ë¯¸ ì—´ë ¤ìˆëŠ” ìƒíƒœ
            if "categoryLayer=OPEN" in self.driver.current_url:
                print("    ì¹´í…Œê³ ë¦¬ íŒ¨ë„ì´ ì´ë¯¸ ì—´ë ¤ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤.")
                return True
            print("    ! ì¹´í…Œê³ ë¦¬ ë©”ë‰´ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

    def click_top_category(self, name):
        """ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ (ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°)"""
        try:
            # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
            selectors = [
                ".category_layer .list_ctgmain a.link_ctg",
                ".category_layer a.link_ctg",
                ".list_ctgmain a.link_ctg",
                ".category_layer a[data-tiara-copy]"
            ]
            
            for selector in selectors:
                els = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for a in els:
                    try:
                        # data-tiara-copy ì†ì„± í™•ì¸
                        tiara_copy = a.get_attribute("data-tiara-copy")
                        if tiara_copy == name:
                            self.js_click(a)
                            self.wait(1.0)
                            return True
                        
                        # í…ìŠ¤íŠ¸ í™•ì¸
                        txt = self.safe_text(a.find_element(By.CSS_SELECTOR, "span.txt_ctg"))
                        if txt == name:
                            self.js_click(a)
                            self.wait(1.0)
                            return True
                    except NoSuchElementException:
                        # ì§ì ‘ í…ìŠ¤íŠ¸ í™•ì¸
                        if self.safe_text(a) == name:
                            self.js_click(a)
                            self.wait(1.0)
                            return True
        except Exception as e:
            print(f"    ! ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

    def click_sub_category(self, name):
        """í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ (íŒ¨ë„ì—ì„œ)"""
        try:
            els = self.driver.find_elements(
                By.CSS_SELECTOR, ".category_layer .list_ctgsub a.link_menu"
            )
            for a in els:
                txt = self.safe_text(a.find_element(By.CSS_SELECTOR, "span.txt_menu"))
                if txt == name:
                    self.js_click(a)
                    self.wait(1.0)
                    return True
        except Exception as e:
            print(f"    ! í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

    def click_all_tab(self):
        """ì „ì²´ íƒ­ í´ë¦­"""
        try:
            # íƒ­ ë²„íŠ¼ë“¤ ì°¾ê¸°
            tab_buttons = self.driver.find_elements(
                By.CSS_SELECTOR, 
                ".module_tab a.link_tab, .rail_cate a.link_tab, a[role='tab']"
            )
            
            for tab in tab_buttons:
                try:
                    # í…ìŠ¤íŠ¸ í™•ì¸
                    text_elem = tab.find_element(By.CSS_SELECTOR, "span.txt_tab, span")
                    if self.safe_text(text_elem) == "ì „ì²´":
                        self.js_click(tab)
                        self.wait(1.0)
                        return True
                except NoSuchElementException:
                    # ì§ì ‘ í…ìŠ¤íŠ¸ í™•ì¸
                    if self.safe_text(tab) == "ì „ì²´":
                        self.js_click(tab)
                        self.wait(1.0)
                        return True
        except Exception as e:
            print(f"    ! ì „ì²´ íƒ­ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

    def click_more_button(self):
        """ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­"""
        try:
            # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
            selectors = [
                "button.btn_more",
                ".btn_more", 
                "button[data-tiara-copy*='ë”ë³´ê¸°']",
                "button[data-tiara-copy*='ìƒí’ˆ ë”ë³´ê¸°']",
                ".button.btn_more",
                "button[class*='btn_more']"
            ]
            
            for selector in selectors:
                try:
                    more_btn = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if more_btn.is_displayed():
                        print(f"        ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬: {selector}")
                        self.js_click(more_btn)
                        self.wait(1.5)  # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                        return True
                except NoSuchElementException:
                    continue
        except Exception as e:
            print(f"        ! ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

    def scroll_to_top(self):
        """í˜ì´ì§€ ë§¨ ìœ„ë¡œ ìŠ¤í¬ë¡¤"""
        self.driver.execute_script("window.scrollTo(0, 0);")
        self.wait(0.5)

    # -------------------- ìŠ¤í¬ë¡¤/ì¹´ë“œ íŒŒì‹± --------------------
    def scroll_until_cards(self, min_cards, has_more_button=False, subcategory=None):
        print(f"        ì¹´ë“œ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        for i in range(6):
            cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
            if len(cards) > 0:
                print(f"        âœ“ ì¹´ë“œ ë°œê²¬: {len(cards)}ê°œ")
                break
            print(f"        ëŒ€ê¸° {i+1}/6...")
            self.wait(0.6)

        # ìŠ¤íƒ€ì•¨ë²”ì€ ì´ì „ ë°©ì‹ (ë”ë³´ê¸° ë²„íŠ¼ ì—¬ëŸ¬ ë²ˆ í´ë¦­)
        if has_more_button and subcategory == "ìŠ¤íƒ€ì•¨ë²”":
            print(f"        ìŠ¤íƒ€ì•¨ë²”: ë”ë³´ê¸° ë²„íŠ¼ ì—¬ëŸ¬ ë²ˆ í´ë¦­ ë°©ì‹")
            last_len, still = 0, 0
            tries = 0
            more_clicks = 0
            
            while True:
                cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                if len(cards) >= min_cards:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ëª©í‘œ: {min_cards}ê°œ ë‹¬ì„±)")
                    break
                if tries >= self.MAX_SCROLL_TRIES:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬)")
                    break
                    
                # ë”ë³´ê¸° ë²„íŠ¼ì´ ìˆëŠ” ê²½ìš° í´ë¦­
                if more_clicks < 20:  # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì œí•œ
                    if self.click_more_button():
                        more_clicks += 1
                        print(f"        ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ {more_clicks}íšŒ")
                        self.wait(1.0)
                        continue
                
                # ìŠ¤í¬ë¡¤
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.wait(self.SCROLL_PAUSE)
                
                cards2 = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                still = still + 1 if len(cards2) == last_len else 0
                last_len = len(cards2)
                tries += 1
                
                if tries % 5 == 0:
                    print(f"        ìŠ¤í¬ë¡¤ {tries}: {len(cards2)}ê°œ (ëª©í‘œ: {min_cards}ê°œ)")
                if still >= 6:
                    print(f"        ë” ì´ìƒ ìƒˆë¡œìš´ ì¹´ë“œê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                    break
        
        # ê²Œì„ì€ í˜„ì¬ ë°©ì‹ (ë”ë³´ê¸° ë²„íŠ¼ í•œ ë²ˆë§Œ í´ë¦­)
        elif has_more_button and subcategory == "ê²Œì„":
            print(f"        ê²Œì„: ë”ë³´ê¸° ë²„íŠ¼ í•œ ë²ˆë§Œ í´ë¦­ ë°©ì‹")
            initial_cards = len(self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li"))
            if self.click_more_button():
                print(f"        âœ“ ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì„±ê³µ, ì¶”ê°€ ë¡œë”© ëŒ€ê¸°...")
                self.wait(3.0)  # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ì¶©ë¶„íˆ ëŒ€ê¸°
                
                # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ìŠ¤í¬ë¡¤ì„ ëª‡ ë²ˆ ë” í•´ì„œ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ
                print(f"        ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ì¶”ê°€ ìŠ¤í¬ë¡¤...")
                for i in range(5):
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    self.wait(1.0)
                    current_cards = len(self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li"))
                    print(f"        ì¶”ê°€ ìŠ¤í¬ë¡¤ {i+1}: {current_cards}ê°œ")
                
                # ìµœì¢… ì¹´ë“œ ìˆ˜ í™•ì¸
                final_cards = len(self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li"))
                print(f"        ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ìµœì¢…: {initial_cards}ê°œ â†’ {final_cards}ê°œ")
            else:
                print(f"        ! ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨")
            
            # ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ëª¨ë“  ì¹´ë“œ ë¡œë“œ
            last_len, still = 0, 0
            tries = 0
            
            while True:
                cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                if len(cards) >= min_cards:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ëª©í‘œ: {min_cards}ê°œ ë‹¬ì„±)")
                    break
                if tries >= self.MAX_SCROLL_TRIES:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬)")
                    break
                
                # ìŠ¤í¬ë¡¤
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.wait(self.SCROLL_PAUSE)
                
                cards2 = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                still = still + 1 if len(cards2) == last_len else 0
                last_len = len(cards2)
                tries += 1
                
                if tries % 5 == 0:
                    print(f"        ìŠ¤í¬ë¡¤ {tries}: {len(cards2)}ê°œ (ëª©í‘œ: {min_cards}ê°œ)")
                if still >= 6:
                    print(f"        ë” ì´ìƒ ìƒˆë¡œìš´ ì¹´ë“œê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                    break
        
        # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” ìŠ¤í¬ë¡¤ë§Œ
        else:
            print(f"        {subcategory}: ìŠ¤í¬ë¡¤ë§Œ ë°©ì‹")
            last_len, still = 0, 0
            tries = 0
            
            while True:
                cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                if len(cards) >= min_cards:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ëª©í‘œ: {min_cards}ê°œ ë‹¬ì„±)")
                    break
                if tries >= self.MAX_SCROLL_TRIES:
                    print(f"        ìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(cards)}ê°œ (ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬)")
                    break
                
                # ìŠ¤í¬ë¡¤
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.wait(self.SCROLL_PAUSE)
                
                cards2 = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
                still = still + 1 if len(cards2) == last_len else 0
                last_len = len(cards2)
                tries += 1
                
                if tries % 5 == 0:
                    print(f"        ìŠ¤í¬ë¡¤ {tries}: {len(cards2)}ê°œ (ëª©í‘œ: {min_cards}ê°œ)")
                if still >= 6:
                    print(f"        ë” ì´ìƒ ìƒˆë¡œìš´ ì¹´ë“œê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                    break

    def parse_card(self, card):
        data = {
            "brand": None,
            "product_name": None,
            "price": None,
            "satisfaction_pct": None,
            "review_count": None,
            "wish_count": None,
            "tags": None,
            "product_url": None,
        }
        
        # ë§í¬
        for sel in ["div.thumb_prd a.link_thumb[href]", "gc-link a.link_info[href]", "a[href]"]:
            try:
                href = card.find_element(By.CSS_SELECTOR, sel).get_attribute("href")
                if href and "/product/" in href:
                    data["product_url"] = urljoin(self.BASE, href)
                    break
            except NoSuchElementException:
                pass
                
        # í…ìŠ¤íŠ¸ë“¤
        try:
            data["brand"] = self.safe_text(card.find_element(By.CSS_SELECTOR, "span.brand_prd"))
        except NoSuchElementException:
            pass
            
        try:
            data["product_name"] = self.safe_text(card.find_element(By.CSS_SELECTOR, "strong.txt_prdname"))
        except NoSuchElementException:
            pass
            
        # ê°€ê²©
        for sel in ["em.num_price", "span.price_info em.num_price", ".price em", ".price_info em"]:
            try:
                data["price"] = self.to_int(self.safe_text(card.find_element(By.CSS_SELECTOR, sel)))
                if data["price"] is not None:
                    break
            except NoSuchElementException:
                pass
                
        # ë§Œì¡±ë„/ë¦¬ë·°
        roots = [card]
        try:
            roots.insert(0, card.find_element(By.CSS_SELECTOR, "div.info_prd"))
        except NoSuchElementException:
            pass
            
        for r in roots:
            if data["satisfaction_pct"] is None:
                try:
                    s = self.safe_text(r.find_element(By.CSS_SELECTOR, "span.txt_star"))
                    m = re.search(r"(\d+)\s*%", s)
                    data["satisfaction_pct"] = int(m.group(1)) if m else None
                except NoSuchElementException:
                    pass
            if data["review_count"] is None:
                try:
                    rv = self.safe_text(r.find_element(By.CSS_SELECTOR, "span.txt_review"))
                    data["review_count"] = self.to_int(rv)
                except NoSuchElementException:
                    pass
                    
        # ìœ„ì‹œ/íƒœê·¸
        try:
            data["wish_count"] = self.to_int(self.safe_text(card.find_element(By.CSS_SELECTOR, "span.num_wsh")))
        except NoSuchElementException:
            pass
            
        try:
            tags = [self.safe_text(t) for t in card.find_elements(By.CSS_SELECTOR, "span.tag_info span.tag_g")]
            data["tags"] = "|".join([t for t in tags if t]) if tags else None
        except NoSuchElementException:
            pass
            
        return data

    def parse_card_from_html(self, soup):
        """BeautifulSoupìœ¼ë¡œ HTML ìŠ¤ëƒ…ìƒ·ì—ì„œ ì¹´ë“œ ì •ë³´ íŒŒì‹±"""
        data = {
            "brand": None,
            "product_name": None,
            "price": None,
            "satisfaction_pct": None,
            "review_count": None,
            "wish_count": None,
            "tags": None,
            "product_url": None,
        }
        
        # ë§í¬
        for sel in ["div.thumb_prd a.link_thumb[href]", "gc-link a.link_info[href]", "a[href]"]:
            link_elem = soup.select_one(sel)
            if link_elem and link_elem.get("href") and "/product/" in link_elem.get("href"):
                data["product_url"] = urljoin(self.BASE, link_elem.get("href"))
                break
        
        # í…ìŠ¤íŠ¸ë“¤
        brand_elem = soup.select_one("span.brand_prd")
        if brand_elem:
            data["brand"] = brand_elem.get_text(strip=True)
        
        name_elem = soup.select_one("strong.txt_prdname")
        if name_elem:
            data["product_name"] = name_elem.get_text(strip=True)
        
        # ê°€ê²©
        for sel in ["em.num_price", "span.price_info em.num_price", ".price em", ".price_info em"]:
            price_elem = soup.select_one(sel)
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                data["price"] = self.to_int(price_text)
                if data["price"] is not None:
                    break
        
        # ë§Œì¡±ë„/ë¦¬ë·°
        info_prd = soup.select_one("div.info_prd")
        roots = [soup]
        if info_prd:
            roots.insert(0, info_prd)
        
        for root in roots:
            if data["satisfaction_pct"] is None:
                star_elem = root.select_one("span.txt_star")
                if star_elem:
                    star_text = star_elem.get_text(strip=True)
                    m = re.search(r"(\d+)\s*%", star_text)
                    data["satisfaction_pct"] = int(m.group(1)) if m else None
            
            if data["review_count"] is None:
                review_elem = root.select_one("span.txt_review")
                if review_elem:
                    review_text = review_elem.get_text(strip=True)
                    data["review_count"] = self.to_int(review_text)
        
        # ìœ„ì‹œ/íƒœê·¸
        wish_elem = soup.select_one("span.num_wsh")
        if wish_elem:
            data["wish_count"] = self.to_int(wish_elem.get_text(strip=True))
        
        tag_elems = soup.select("span.tag_info span.tag_g")
        if tag_elems:
            tags = [tag.get_text(strip=True) for tag in tag_elems if tag.get_text(strip=True)]
            data["tags"] = "|".join(tags) if tags else None
        
        return data

    def collect_current_page(self, want_total, meta, seen_urls, has_more_button=False, already_collected=0):
        print(f"      ìŠ¤í¬ë¡¤ ì‹œì‘ (ëª©í‘œ: {want_total}ê°œ, ë”ë³´ê¸°ë²„íŠ¼: {'ìˆìŒ' if has_more_button else 'ì—†ìŒ'})...")
        subcategory = meta.get("sub_category")
        self.scroll_until_cards(max(already_collected, want_total), has_more_button, subcategory)
        
        # ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
        cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
        print(f"      ë°œê²¬ëœ ìƒí’ˆ ì¹´ë“œ: {len(cards)}ê°œ")
        
        if len(cards) == 0:
            # ë‹¤ë¥¸ ì„ íƒì ì‹œë„
            alternative_selectors = [
                ".list_prd li",
                ".list_product li", 
                ".product_list li",
                ".item_list li",
                "[class*='product'] li",
                "[class*='item'] li"
            ]
            for selector in alternative_selectors:
                cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if len(cards) > 0:
                    print(f"      ëŒ€ì²´ ì„ íƒì '{selector}'ë¡œ {len(cards)}ê°œ ë°œê²¬")
                    break
        
        # ìŠ¤ëƒ…ìƒ· íŒŒì‹±ìœ¼ë¡œ stale ê·¼ë³¸ ì°¨ë‹¨
        print(f"      HTML ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì¤‘...")
        html_snaps = []
        for i, c in enumerate(cards):
            try:
                html_snaps.append(c.get_attribute("outerHTML"))
            except Exception as e:
                print(f"        ! ì¹´ë“œ {i} HTML ì¶”ì¶œ ì‹¤íŒ¨: {str(e)[:30]}...")
                continue
        
        print(f"      ìŠ¤ëƒ…ìƒ· {len(html_snaps)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ, íŒŒì‹± ì‹œì‘...")
        
        rows, new_count = [], 0
        for i, html in enumerate(html_snaps):
            try:
                soup = BeautifulSoup(html, "html.parser")
                item = self.parse_card_from_html(soup)
                url = item.get("product_url")
                if not url or url in seen_urls:
                    continue
                rows.append({**item, **meta})
                seen_urls.add(url)
                new_count += 1
                if already_collected + new_count >= want_total:
                    break
                if new_count % 10 == 0:
                    print(f"        ì§„í–‰: {new_count}ê°œ ìˆ˜ì§‘ë¨")
            except Exception as e:
                print(f"        ! ìŠ¤ëƒ…ìƒ· {i} íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}...")
                continue
        
        print(f"      ìµœì¢… ìˆ˜ì§‘: {new_count}ê°œ")
        return rows, new_count

    # -------------------- ìˆ˜ì§‘ê¸° --------------------
    def crawl_subcategory(self, subcategory, n):
        """í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘"""
        print(f"[ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„° > {subcategory}] ìˆ˜ì§‘ ì‹œì‘")
        
        # ì „ì²´ íƒ­ í™œì„±í™”
        print(f"    ì „ì²´ íƒ­ í™œì„±í™” ì‹œë„...")
        if self.click_all_tab():
            print(f"    âœ“ ì „ì²´ íƒ­ í™œì„±í™” ì„±ê³µ")
        else:
            print(f"    ! ì „ì²´ íƒ­ í™œì„±í™” ì‹¤íŒ¨, í˜„ì¬ íƒ­ìœ¼ë¡œ ì§„í–‰")
        
        # í˜„ì¬ í˜ì´ì§€ URL í™•ì¸
        current_url = self.driver.current_url
        print(f"    í˜„ì¬ URL: {current_url}")
        
        # ë”ë³´ê¸° ë²„íŠ¼ ìœ ë¬´ í™•ì¸
        has_more_button = False
        try:
            more_btn = self.driver.find_element(By.CSS_SELECTOR, "button.btn_more, .btn_more")
            has_more_button = more_btn.is_displayed()
        except NoSuchElementException:
            pass
        
        print(f"    ë”ë³´ê¸° ë²„íŠ¼: {'ìˆìŒ' if has_more_button else 'ì—†ìŒ'}")
        
        # ìƒí’ˆ ì¹´ë“œ ìˆ˜ì§‘
        print(f"    ìƒí’ˆ ì¹´ë“œ ìˆ˜ì§‘ ì‹œì‘ (ëª©í‘œ: {n}ê°œ)...")
        rows, collected = self.collect_current_page(
            n,
            {"top_category": "ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°", "sub_category": subcategory, "sub_tab": "ì „ì²´"},
            set(),
            has_more_button,
            0,
        )
        print(f"    âœ“ ìˆ˜ì§‘ ì™„ë£Œ: {collected}ê°œ")
        return rows

    # -------------------- 2) í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ --------------------
    def scrape_data(self):
        self.driver.get(self.start_url)
        self.wait(1.2)
        self.all_rows = []

        for subcategory in self.ARTIST_SUBCATEGORIES:
            print(f"\n=== í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì‹œì‘: {subcategory} ===")
            
            # ë§¤ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì§„ì… ì‹œ í•­ìƒ OPEN í˜ì´ì§€ë¡œ ë¦¬ì…‹
            self.driver.get(self.DEFAULT_START)
            self.wait(1.2)
            
            # íŒ¨ë„ ì—´ê¸° ë³´ì¥
            self.ensure_category_panel()
            
            # ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„° ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­
            print(f"  ìƒìœ„ ì¹´í…Œê³ ë¦¬ 'ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°' í´ë¦­ ì‹œë„...")
            if not self.click_top_category("ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°"):
                print(f"  ! ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì‹¤íŒ¨: ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°")
                continue
            print(f"  âœ“ ìƒìœ„ ì¹´í…Œê³ ë¦¬ 'ì•„í‹°ìŠ¤íŠ¸/ìºë¦­í„°' í´ë¦­ ì„±ê³µ")

            # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­
            print(f"  í•˜ìœ„ ì¹´í…Œê³ ë¦¬ '{subcategory}' í´ë¦­ ì‹œë„...")
            if not self.click_sub_category(subcategory):
                print(f"    ! í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì‹¤íŒ¨: {subcategory}")
                continue
            print(f"    âœ“ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ '{subcategory}' í´ë¦­ ì„±ê³µ")

            # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘
            try:
                rows = self.crawl_subcategory(subcategory, self.items_per_subcat)
                self.all_rows.extend(rows)
                print(f"    âœ“ {subcategory}: {len(rows)}ê°œ ìˆ˜ì§‘")
                # ê° í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì¦‰ì‹œ ì €ì¥
                if rows:
                    self.save_to_database(rows, append_mode=True)
                    print(f"    ğŸ’¾ {subcategory} ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"    ! {subcategory} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

            print(f"\n=== {subcategory} ì¹´í…Œê³ ë¦¬ ì™„ë£Œ: {len([r for r in self.all_rows if r.get('sub_category') == subcategory])}ê°œ ìˆ˜ì§‘ ===")

        return self.all_rows

    # -------------------- 3) ì €ì¥ --------------------
    def save_to_database(self, data, append_mode=False):
        df = pd.DataFrame(data)
        if df.empty:
            print("ìˆ˜ì§‘ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        df.drop_duplicates(subset=["product_url"], inplace=True)
        cols = [
            "top_category", "sub_category", "sub_tab",
            "brand", "product_name", "price",
            "satisfaction_pct", "review_count", "wish_count",
            "tags", "product_url",
        ]
        df = df[[c for c in cols if c in df.columns]]
        
        if append_mode and os.path.exists(self.output_path):
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¶”ê°€ ëª¨ë“œë¡œ ì €ì¥
            df.to_csv(self.output_path, mode='a', header=False, index=False, encoding="utf-8-sig")
            print(f"ì¶”ê°€ ì €ì¥ ì™„ë£Œ: {self.output_path} (+{len(df)}ê°œ)")
        else:
            # ìƒˆ íŒŒì¼ë¡œ ì €ì¥
            df.to_csv(self.output_path, index=False, encoding="utf-8-sig")
            print(f"ì €ì¥ ì™„ë£Œ: {self.output_path} (ì´ {len(df)}ê°œ)")

    # -------------------- íŒŒì´í”„ë¼ì¸ --------------------
    def run(self):
        self.start_browser()
        try:
            data = self.scrape_data()
            # ë§ˆì§€ë§‰ì— ì „ì²´ ë°ì´í„°ë„ ì €ì¥ (ì¤‘ë³µ ì œê±° í¬í•¨)
            if data:
                print(f"\n=== ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {len(data)}ê°œ ===")
                self.save_to_database(data, append_mode=False)
        finally:
            self.close_browser()


# ì§ì ‘ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    import os
    output_dir = os.path.join(os.getcwd(), "..", "raw_data")
    crawler = KakaoGiftArtistCrawler(
        output_dir=output_dir,
        output_filename="kakao_gifts_artist.csv",
        headless=False,
        items_per_subcat=300,
        start_url=None
    )
    crawler.run()
