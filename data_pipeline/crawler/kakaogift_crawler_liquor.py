# -*- coding: utf-8 -*-
import os
import re
import time
from urllib.parse import urljoin

import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, WebDriverException, TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

from base_crawler import BaseCrawler


class KakaoGiftLiquorCrawler(BaseCrawler):
    """
    ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ ì¹´í…Œê³ ë¦¬ ì „ìš© í¬ë¡¤ëŸ¬
    - ìƒìœ„ ì¹´í…Œê³ ë¦¬: ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼
    - í•˜ìœ„ ì¹´í…Œê³ ë¦¬: ì™€ì¸(75ê°œì”©), ì–‘ì£¼(60ê°œì”©), ë§¥ì£¼/ê¸°íƒ€(75ê°œì”©)
    - íë¦„: ìƒìœ„ ì¹´í…Œê³ ë¦¬ â†’ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ â†’ ê°€ê²©ëŒ€ë³„ íƒ­ â†’ ë”ë³´ê¸° ë²„íŠ¼ìœ¼ë¡œ ìˆ˜ì§‘
    - ì¹´ë“œ í•„ë“œ: brand, product_name, price, satisfaction_pct, review_count,
                wish_count, tags, product_url, price_range
    """

    BASE = "https://gift.kakao.com"
    DEFAULT_START = "https://gift.kakao.com/home?categoryLayer=OPEN"

    # ë™ì‘ íŒŒë¼ë¯¸í„°
    SCROLL_PAUSE = 1.0
    CLICK_PAUSE = 0.8
    LOAD_PAUSE = 2.0
    IMPLICIT_WAIT = 10
    EXPLICIT_WAIT = 15

    # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ ê°œìˆ˜
    SUB_CATEGORY_TARGETS = {
        "ì™€ì¸": 75,
        "ì–‘ì£¼": 60,
        "ë§¥ì£¼/ê¸°íƒ€": 75
    }

    # ê°€ê²©ëŒ€ íƒ­ ì„ íƒìë“¤ (ê°€ê²©ëŒ€ë³„ í•„í„° íƒ­)
    PRICE_TAB_SELECTORS = [
        ".module_tab.module_tab_bubble .rail_cate a.link_tab",
        ".module_tab .rail_cate a.link_tab",
        ".rail_cate a.link_tab",
        ".module_tab_wrapper .link_tab",
        ".module_tab.module_tab_keyword .link_tab"
    ]
    
    # ê°€ê²©ëŒ€ íƒ­ í…ìŠ¤íŠ¸ íŒ¨í„´ (ê°€ê²©ëŒ€ë§Œ í•„í„°ë§)
    PRICE_RANGE_PATTERNS = [
        r"~?\d+ë§Œ?ì›ëŒ€?",
        r"\d+~?\d*ë§Œ?ì›",
        r"\d+ë§Œ?ì›\s*ì´ìƒ",
        r"\d+ë§Œ?ì›\s*~",
        r"~\d+ë§Œ?ì›"
    ]

    # ë”ë³´ê¸° ë²„íŠ¼ ì„ íƒìë“¤
    MORE_BUTTON_SELECTORS = [
        "button.btn_more",
        ".module_bottom_btn button.btn_more",
        "button[data-tiara-copy*='ë”ë³´ê¸°']",
        ".btn_more"
    ]

    def __init__(
        self,
        output_dir: str,
        *,
        output_filename: str = "kakao_gifts_liquor.csv",
        headless: bool = False,
        start_url: str | None = None,
    ):
        super().__init__(output_dir=output_dir)
        self.output_path = os.path.join(output_dir, output_filename)

        self.headless = headless
        self.start_url = start_url or self.DEFAULT_START

        self.driver = None
        self.wait = None
        self.all_rows = []

    # -------------------- 1) ë¸Œë¼ìš°ì € --------------------
    def start_browser(self):
        opts = Options()
        if self.headless:
            opts.add_argument("--headless=new")
        opts.add_argument("--window-size=1500,1100")
        opts.add_argument("--no-sandbox")
        opts.add_argument("--disable-gpu")
        opts.add_argument("--lang=ko-KR")
        opts.add_argument("--disable-dev-shm-usage")
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=opts)
        self.driver.implicitly_wait(self.IMPLICIT_WAIT)
        self.wait = WebDriverWait(self.driver, self.EXPLICIT_WAIT)

    # -------------------- ìœ í‹¸ --------------------
    def sleep(self, t=None):
        time.sleep(t if t is not None else self.SCROLL_PAUSE)

    def js_click(self, el):
        try:
            self.driver.execute_script("arguments[0].click();", el)
        except WebDriverException:
            try:
                el.click()
            except Exception:
                pass
        self.sleep(self.CLICK_PAUSE)

    @staticmethod
    def safe_text(el):
        try:
            return el.text.strip()
        except Exception:
            return ""

    @staticmethod
    def to_int(text):
        if not text:
            return None
        s = re.sub(r"[^\dë§Œ\+,\s]", "", text).replace(",", "").replace(" ", "")
        if "ë§Œ+" in s:
            try:
                return int(s.replace("ë§Œ+", "")) * 10000
            except Exception:
                return None
        if "ë§Œ" in s:
            try:
                return int(s.replace("ë§Œ", "")) * 10000
            except Exception:
                pass
        try:
            return int(re.sub(r"[^\d]", "", s))
        except Exception:
            return None

    # -------------------- ì¹´í…Œê³ ë¦¬ ë„¤ë¹„ê²Œì´ì…˜ --------------------
    def category_panel_open(self) -> bool:
        """ì¹´í…Œê³ ë¦¬ íŒ¨ë„(ì¢Œì¸¡ ë ˆì´ì–´)ì´ ì—´ë ¤ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            self.driver.find_element(By.CSS_SELECTOR, ".category_layer .list_ctgmenu")
            return True
        except NoSuchElementException:
            return False

    def click_header_category_button(self) -> bool:
        """í—¤ë”ì˜ 'ì¹´í…Œê³ ë¦¬' ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒ¨ë„ì„ ì—°ë‹¤."""
        selectors = [
            "button.btn_cate",
            "div.group_head button.btn_cate",
            "button[aria-label='ì¹´í…Œê³ ë¦¬']",
            "a[aria-label='ì¹´í…Œê³ ë¦¬']",
            "a[href*='categoryLayer']",
        ]
        for sel in selectors:
            try:
                btn = self.driver.find_element(By.CSS_SELECTOR, sel)
                self.js_click(btn)
                self.sleep(0.8)
                if self.category_panel_open():
                    return True
            except (NoSuchElementException, StaleElementReferenceException):
                continue
        return False

    def ensure_category_panel(self):
        """ì¹´í…Œê³ ë¦¬ íŒ¨ë„ì„ ë°˜ë“œì‹œ ì—°ë‹¤."""
        if self.category_panel_open():
            return
        if not self.click_header_category_button():
            self.driver.get(self.DEFAULT_START)
            self.sleep(1.5)

    def click_top_category(self, name):
        """ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­"""
        els = self.driver.find_elements(
            By.CSS_SELECTOR, ".category_layer .list_ctgmenu a.link_menu"
        )
        for a in els:
            txt = self.safe_text(a.find_element(By.CSS_SELECTOR, "span.txt_menu"))
            if txt == name:
                self.js_click(a)
                self.sleep(1.0)
                return True
        return False

    def click_sub_category(self, name):
        """í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­"""
        els = self.driver.find_elements(
            By.CSS_SELECTOR, ".category_layer .list_ctgsub a.link_menu"
        )
        for a in els:
            txt = self.safe_text(a.find_element(By.CSS_SELECTOR, "span.txt_menu"))
            if txt == name:
                self.js_click(a)
                self.sleep(1.5)
                return True
        return False

    # -------------------- ê°€ê²©ëŒ€ íƒ­ ì œì–´ --------------------
    def get_price_tabs(self):
        """ê°€ê²©ëŒ€ íƒ­ë“¤ì„ ì°¾ì•„ì„œ í…ìŠ¤íŠ¸ì™€ ìš”ì†Œë¥¼ ë°˜í™˜"""
        price_tabs = []
        
        for selector in self.PRICE_TAB_SELECTORS:
            try:
                tabs = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if tabs:
                    for tab in tabs:
                        try:
                            text = self.safe_text(tab.find_element(By.CSS_SELECTOR, "span.txt_tab"))
                        except NoSuchElementException:
                            # span.txt_tabì´ ì—†ëŠ” ê²½ìš° ì§ì ‘ í…ìŠ¤íŠ¸ í™•ì¸
                            text = self.safe_text(tab)
                        
                        # ê°€ê²©ëŒ€ íŒ¨í„´ì— ë§ëŠ” í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
                        if text and self.is_price_range_tab(text) and text not in [t[0] for t in price_tabs]:
                            price_tabs.append((text, tab))
                    
                    if price_tabs:
                        break
            except Exception:
                continue
        
        return price_tabs
    
    def is_price_range_tab(self, text):
        """í…ìŠ¤íŠ¸ê°€ ê°€ê²©ëŒ€ íƒ­ì¸ì§€ í™•ì¸"""
        import re
        for pattern in self.PRICE_RANGE_PATTERNS:
            if re.search(pattern, text):
                return True
        return False

    def click_price_tab(self, tab_element):
        """ê°€ê²©ëŒ€ íƒ­ í´ë¦­"""
        try:
            self.js_click(tab_element)
            self.sleep(self.LOAD_PAUSE)
            return True
        except Exception as e:
            print(f"        ! ê°€ê²©ëŒ€ íƒ­ í´ë¦­ ì‹¤íŒ¨: {e}")
            return False

    # -------------------- ë”ë³´ê¸° ë²„íŠ¼ ì œì–´ --------------------
    def find_more_button(self):
        """ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°"""
        for selector in self.MORE_BUTTON_SELECTORS:
            try:
                button = self.driver.find_element(By.CSS_SELECTOR, selector)
                if button.is_displayed():
                    return button
            except NoSuchElementException:
                continue
        return None

    def click_more_button(self):
        """ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­"""
        button = self.find_more_button()
        if button:
            try:
                # ë²„íŠ¼ì´ í´ë¦­ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸
                if not button.is_enabled() or not button.is_displayed():
                    print(f"        ! ë”ë³´ê¸° ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŒ")
                    return False
                
                # í˜„ì¬ ìƒí’ˆ ê°œìˆ˜ ì €ì¥
                before_count = len(self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li"))
                
                # ë²„íŠ¼ì´ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
                self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                self.sleep(0.5)
                
                # í´ë¦­ ì‹œë„
                self.js_click(button)
                
                # ë¡œë”© ëŒ€ê¸° (ë” ê¸¸ê²Œ)
                self.sleep(self.LOAD_PAUSE + 2.0)
                
                # ìƒí’ˆ ê°œìˆ˜ê°€ ì¦ê°€í–ˆëŠ”ì§€ í™•ì¸
                after_count = len(self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li"))
                if before_count == after_count:
                    print(f"        ! ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ í›„ ìƒí’ˆ ê°œìˆ˜ ë³€í™” ì—†ìŒ (ì´ì „: {before_count}, í˜„ì¬: {after_count})")
                    return False
                else:
                    print(f"        ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì„±ê³µ: {before_count}ê°œ â†’ {after_count}ê°œ (+{after_count - before_count}ê°œ)")
                
                return True
            except Exception as e:
                print(f"        ! ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}")
                return False
        return False

    # -------------------- ìƒí’ˆ ì¹´ë“œ íŒŒì‹± --------------------
    def parse_card(self, card):
        """ìƒí’ˆ ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        data = {
            "brand": None,
            "product_name": None,
            "price": None,
            "satisfaction_pct": None,
            "review_count": None,
            "wish_count": None,
            "tags": None,
            "product_url": None,
        }
        
        # ë§í¬
        for sel in ["div.thumb_prd a.link_thumb[href]", "gc-link a.link_info[href]"]:
            try:
                href = card.find_element(By.CSS_SELECTOR, sel).get_attribute("href")
                if href:
                    data["product_url"] = urljoin(self.BASE, href)
                    break
            except NoSuchElementException:
                pass
        
        # í…ìŠ¤íŠ¸ë“¤
        try:
            data["brand"] = self.safe_text(card.find_element(By.CSS_SELECTOR, "span.brand_prd"))
        except NoSuchElementException:
            pass
        
        try:
            data["product_name"] = self.safe_text(card.find_element(By.CSS_SELECTOR, "strong.txt_prdname"))
        except NoSuchElementException:
            pass
        
        # ê°€ê²©
        for sel in ["em.num_price", "span.price_info em.num_price"]:
            try:
                data["price"] = self.to_int(self.safe_text(card.find_element(By.CSS_SELECTOR, sel)))
                if data["price"] is not None:
                    break
            except NoSuchElementException:
                pass
        
        # ë§Œì¡±ë„/ë¦¬ë·°
        roots = [card]
        try:
            roots.insert(0, card.find_element(By.CSS_SELECTOR, "div.info_prd"))
        except NoSuchElementException:
            pass
        
        for r in roots:
            if data["satisfaction_pct"] is None:
                try:
                    s = self.safe_text(r.find_element(By.CSS_SELECTOR, "span.txt_star"))
                    m = re.search(r"(\d+)\s*%", s)
                    data["satisfaction_pct"] = int(m.group(1)) if m else None
                except NoSuchElementException:
                    pass
            
            if data["review_count"] is None:
                try:
                    rv = self.safe_text(r.find_element(By.CSS_SELECTOR, "span.txt_review"))
                    data["review_count"] = self.to_int(rv)
                except NoSuchElementException:
                    pass
        
        # ìœ„ì‹œ/íƒœê·¸
        try:
            data["wish_count"] = self.to_int(self.safe_text(card.find_element(By.CSS_SELECTOR, "span.num_wsh")))
        except NoSuchElementException:
            pass
        
        try:
            tags = [self.safe_text(t) for t in card.find_elements(By.CSS_SELECTOR, "span.tag_info span.tag_g")]
            data["tags"] = "|".join([t for t in tags if t]) if tags else None
        except NoSuchElementException:
            pass
        
        return data

    def parse_card_from_html(self, soup):
        """BeautifulSoupìœ¼ë¡œ HTML ìŠ¤ëƒ…ìƒ·ì—ì„œ ì¹´ë“œ ì •ë³´ íŒŒì‹±"""
        data = {
            "brand": None,
            "product_name": None,
            "price": None,
            "satisfaction_pct": None,
            "review_count": None,
            "wish_count": None,
            "tags": None,
            "product_url": None,
        }
        
        # ë§í¬
        for sel in ["div.thumb_prd a.link_thumb[href]", "gc-link a.link_info[href]"]:
            link_elem = soup.select_one(sel)
            if link_elem and link_elem.get("href"):
                data["product_url"] = urljoin(self.BASE, link_elem.get("href"))
                break
        
        # í…ìŠ¤íŠ¸ë“¤
        brand_elem = soup.select_one("span.brand_prd")
        if brand_elem:
            data["brand"] = brand_elem.get_text(strip=True)
        
        name_elem = soup.select_one("strong.txt_prdname")
        if name_elem:
            data["product_name"] = name_elem.get_text(strip=True)
        
        # ê°€ê²©
        for sel in ["em.num_price", "span.price_info em.num_price"]:
            price_elem = soup.select_one(sel)
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                data["price"] = self.to_int(price_text)
                if data["price"] is not None:
                    break
        
        # ë§Œì¡±ë„/ë¦¬ë·°
        info_prd = soup.select_one("div.info_prd")
        roots = [soup]
        if info_prd:
            roots.insert(0, info_prd)
        
        for root in roots:
            if data["satisfaction_pct"] is None:
                star_elem = root.select_one("span.txt_star")
                if star_elem:
                    star_text = star_elem.get_text(strip=True)
                    m = re.search(r"(\d+)\s*%", star_text)
                    data["satisfaction_pct"] = int(m.group(1)) if m else None
            
            if data["review_count"] is None:
                review_elem = root.select_one("span.txt_review")
                if review_elem:
                    review_text = review_elem.get_text(strip=True)
                    data["review_count"] = self.to_int(review_text)
        
        # ìœ„ì‹œ/íƒœê·¸
        wish_elem = soup.select_one("span.num_wsh")
        if wish_elem:
            data["wish_count"] = self.to_int(wish_elem.get_text(strip=True))
        
        tag_elems = soup.select("span.tag_info span.tag_g")
        if tag_elems:
            tags = [tag.get_text(strip=True) for tag in tag_elems if tag.get_text(strip=True)]
            data["tags"] = "|".join(tags) if tags else None
        
        return data

    # -------------------- ìƒí’ˆ ìˆ˜ì§‘ --------------------
    def collect_products_in_price_range(self, target_count, price_range, meta, seen_urls):
        """íŠ¹ì • ê°€ê²©ëŒ€ì—ì„œ ëª©í‘œ ê°œìˆ˜ë§Œí¼ ìƒí’ˆ ìˆ˜ì§‘ (ëª©í‘œ ë¯¸ë‹¬ì„± ì‹œì—ë„ ìˆ˜ì§‘ ì¤‘ë‹¨)"""
        print(f"        ê°€ê²©ëŒ€ '{price_range}'ì—ì„œ {target_count}ê°œ ìˆ˜ì§‘ ì‹œì‘...")
        
        collected_count = 0
        more_clicks = 0
        max_more_clicks = 20  # ë¬´í•œ ë£¨í”„ ë°©ì§€
        consecutive_no_new_items = 0  # ì—°ì†ìœ¼ë¡œ ìƒˆ ì•„ì´í…œì´ ì—†ëŠ” íšŸìˆ˜
        
        while collected_count < target_count and more_clicks < max_more_clicks:
            # í˜„ì¬ í˜ì´ì§€ì˜ ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
            cards = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_prd > li")
            
            if len(cards) == 0:
                # ë‹¤ë¥¸ ì„ íƒì ì‹œë„
                alternative_selectors = [
                    ".list_prd li",
                    ".list_product li", 
                    ".product_list li",
                    ".item_list li",
                    "[class*='product'] li",
                    "[class*='item'] li"
                ]
                for selector in alternative_selectors:
                    cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if len(cards) > 0:
                        print(f"        ëŒ€ì²´ ì„ íƒì '{selector}'ë¡œ {len(cards)}ê°œ ë°œê²¬")
                        break
            
            if len(cards) == 0:
                print(f"        ! ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                break
            
            # HTML ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘
            html_snaps = []
            for i, c in enumerate(cards):
                try:
                    html_snaps.append(c.get_attribute("outerHTML"))
                except Exception as e:
                    print(f"          ! ì¹´ë“œ {i} HTML ì¶”ì¶œ ì‹¤íŒ¨: {str(e)[:30]}...")
                    continue
            
            # ìŠ¤ëƒ…ìƒ· íŒŒì‹±
            new_items = []
            for i, html in enumerate(html_snaps):
                try:
                    soup = BeautifulSoup(html, "html.parser")
                    item = self.parse_card_from_html(soup)
                    url = item.get("product_url")
                    if not url or url in seen_urls:
                        continue
                    
                    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    item.update(meta)
                    item["price_range"] = price_range
                    
                    new_items.append(item)
                    seen_urls.add(url)
                    
                    if collected_count + len(new_items) >= target_count:
                        break
                        
                except Exception as e:
                    print(f"          ! ìŠ¤ëƒ…ìƒ· {i} íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}...")
                    continue
            
            # ìˆ˜ì§‘ëœ ì•„ì´í…œ ì¶”ê°€
            self.all_rows.extend(new_items)
            collected_count += len(new_items)
            
            print(f"        ì§„í–‰: {collected_count}/{target_count}ê°œ ìˆ˜ì§‘ë¨")
            
            # ëª©í‘œ ë‹¬ì„±í–ˆìœ¼ë©´ ì¢…ë£Œ
            if collected_count >= target_count:
                break
            
            # ìƒˆ ì•„ì´í…œì´ ì—†ìœ¼ë©´ ì¹´ìš´íŠ¸ ì¦ê°€
            if len(new_items) == 0:
                consecutive_no_new_items += 1
                if consecutive_no_new_items >= 3:  # 3ë²ˆ ì—°ì†ìœ¼ë¡œ ìƒˆ ì•„ì´í…œì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                    print(f"        ì—°ì†ìœ¼ë¡œ ìƒˆ ì•„ì´í…œì´ ì—†ì–´ì„œ ìˆ˜ì§‘ ì¤‘ë‹¨")
                    break
            else:
                consecutive_no_new_items = 0  # ìƒˆ ì•„ì´í…œì´ ìˆìœ¼ë©´ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            
            # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì‹œë„
            if self.click_more_button():
                more_clicks += 1
                print(f"        ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ({more_clicks}ë²ˆì§¸)")
            else:
                print(f"        ë”ë³´ê¸° ë²„íŠ¼ì´ ì—†ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŒ")
                break
        
        print(f"        âœ“ ê°€ê²©ëŒ€ '{price_range}' ì™„ë£Œ: {collected_count}ê°œ ìˆ˜ì§‘")
        return collected_count

    def crawl_sub_category(self, top_category, sub_category):
        """í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘"""
        print(f"    [{top_category} > {sub_category}] ìˆ˜ì§‘ ì‹œì‘")
        
        target_count = self.SUB_CATEGORY_TARGETS.get(sub_category, 75)
        print(f"    ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜: {target_count}ê°œ")
        
        # ê°€ê²©ëŒ€ íƒ­ë“¤ ì°¾ê¸°
        price_tabs = self.get_price_tabs()
        if not price_tabs:
            print(f"    ! ê°€ê²©ëŒ€ íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return
        
        print(f"    ë°œê²¬ëœ ê°€ê²©ëŒ€ íƒ­: {[tab[0] for tab in price_tabs]}")
        
        total_collected = 0
        seen_urls = set()
        
        # ê° ê°€ê²©ëŒ€ë³„ë¡œ ìˆ˜ì§‘
        for price_range, tab_element in price_tabs:
            print(f"      ê°€ê²©ëŒ€ '{price_range}' íƒ­ í´ë¦­...")
            
            if not self.click_price_tab(tab_element):
                print(f"      ! ê°€ê²©ëŒ€ íƒ­ í´ë¦­ ì‹¤íŒ¨: {price_range}")
                continue
            
            # í•´ë‹¹ ê°€ê²©ëŒ€ì—ì„œ ìˆ˜ì§‘
            meta = {
                "top_category": top_category,
                "sub_category": sub_category,
                "sub_tab": None
            }
            
            collected = self.collect_products_in_price_range(
                target_count, price_range, meta, seen_urls
            )
            total_collected += collected
            
            # ì¦‰ì‹œ ì €ì¥
            if collected > 0:
                recent_items = [item for item in self.all_rows[-collected:] if item.get("price_range") == price_range]
                self.save_to_database(recent_items, append_mode=True)
                print(f"      ğŸ’¾ {price_range} ì €ì¥ ì™„ë£Œ ({collected}ê°œ)")
        
        print(f"    âœ“ {sub_category} ì™„ë£Œ: ì´ {total_collected}ê°œ ìˆ˜ì§‘")
        return total_collected

    # -------------------- 2) í¬ë¡¤ë§ íŒŒì´í”„ë¼ì¸ --------------------
    def scrape_data(self):
        self.driver.get(self.start_url)
        self.sleep(1.5)
        self.ensure_category_panel()
        self.all_rows = []

        # ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­
        print("=== ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ ì¹´í…Œê³ ë¦¬ ì‹œì‘ ===")
        if not self.click_top_category("ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼"):
            print("! ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì‹¤íŒ¨")
            return []

        # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë“¤ ìˆœíšŒ
        sub_categories = ["ì™€ì¸", "ì–‘ì£¼", "ë§¥ì£¼/ê¸°íƒ€"]
        
        for sub_category in sub_categories:
            print(f"\n--- {sub_category} í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì‹œì‘ ---")
            
            # ë§¤ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì‹œì‘ ì‹œ ë©”ì¸ í˜ì´ì§€ë¡œ ë¦¬ì…‹
            self.driver.get(self.DEFAULT_START)
            self.sleep(1.5)
            self.ensure_category_panel()
            
            # ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­
            if not self.click_top_category("ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼"):
                print(f"! ìƒìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì‹¤íŒ¨")
                continue
            
            # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­
            if not self.click_sub_category(sub_category):
                print(f"! í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í´ë¦­ ì‹¤íŒ¨: {sub_category}")
                continue
            
            # í•´ë‹¹ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘
            try:
                self.crawl_sub_category("ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼", sub_category)
            except Exception as e:
                print(f"! {sub_category} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

        print(f"\n=== ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {len(self.all_rows)}ê°œ ìˆ˜ì§‘ ===")
        return self.all_rows

    # -------------------- 3) ì €ì¥ --------------------
    def save_to_database(self, data, append_mode=False):
        df = pd.DataFrame(data)
        if df.empty:
            print("ìˆ˜ì§‘ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        df.drop_duplicates(subset=["product_url"], inplace=True)
        cols = [
            "top_category", "sub_category", "sub_tab", "price_range",
            "brand", "product_name", "price",
            "satisfaction_pct", "review_count", "wish_count",
            "tags", "product_url",
        ]
        df = df[[c for c in cols if c in df.columns]]
        
        if append_mode and os.path.exists(self.output_path):
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¶”ê°€ ëª¨ë“œë¡œ ì €ì¥
            df.to_csv(self.output_path, mode='a', header=False, index=False, encoding="utf-8-sig")
            print(f"ì¶”ê°€ ì €ì¥ ì™„ë£Œ: {self.output_path} (+{len(df)}ê°œ)")
        else:
            # ìƒˆ íŒŒì¼ë¡œ ì €ì¥
            df.to_csv(self.output_path, index=False, encoding="utf-8-sig")
            print(f"ì €ì¥ ì™„ë£Œ: {self.output_path} (ì´ {len(df)}ê°œ)")

    # -------------------- íŒŒì´í”„ë¼ì¸ --------------------
    def run(self):
        self.start_browser()
        try:
            data = self.scrape_data()
            # ë§ˆì§€ë§‰ì— ì „ì²´ ë°ì´í„°ë„ ì €ì¥ (ì¤‘ë³µ ì œê±° í¬í•¨)
            if data:
                print(f"\n=== ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {len(data)}ê°œ ===")
                self.save_to_database(data, append_mode=False)
        finally:
            self.close_browser()


# ì§ì ‘ ì‹¤í–‰ ì‹œ ì‚¬ìš©í•  ë©”ì¸ í•¨ìˆ˜
def main():
    """ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹¤í–‰"""
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (raw_data í´ë”)
    current_dir = Path(__file__).parent
    output_dir = current_dir.parent / "raw_data"
    output_dir.mkdir(exist_ok=True)
    
    print("=== ì¹´ì¹´ì˜¤ ê¸°í”„íŠ¸ ì™€ì¸/ì–‘ì£¼/ì „í†µì£¼ í¬ë¡¤ëŸ¬ ì‹œì‘ ===")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = KakaoGiftLiquorCrawler(
        output_dir=str(output_dir),
        output_filename="kakao_gifts_liquor.csv",
        headless=False,  # ë¸Œë¼ìš°ì € ì°½ì„ ë³´ë©´ì„œ ì‹¤í–‰í•˜ë ¤ë©´ False
    )
    
    try:
        # í¬ë¡¤ë§ ì‹¤í–‰
        crawler.run()
        print("\n=== í¬ë¡¤ë§ ì™„ë£Œ ===")
        
        # ê²°ê³¼ í™•ì¸
        output_file = output_dir / "kakao_gifts_liquor.csv"
        if output_file.exists():
            import pandas as pd
            df = pd.read_csv(output_file)
            print(f"ìˆ˜ì§‘ëœ ì´ ìƒí’ˆ ìˆ˜: {len(df)}ê°œ")
            print(f"íŒŒì¼ ìœ„ì¹˜: {output_file}")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            if 'sub_category' in df.columns:
                print("\nì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™©:")
                category_stats = df['sub_category'].value_counts()
                for category, count in category_stats.items():
                    print(f"  {category}: {count}ê°œ")
            
            if 'price_range' in df.columns:
                print("\nê°€ê²©ëŒ€ë³„ ìˆ˜ì§‘ í˜„í™©:")
                price_stats = df['price_range'].value_counts()
                for price_range, count in price_stats.items():
                    print(f"  {price_range}: {count}ê°œ")
        else:
            print("! ì¶œë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
    except KeyboardInterrupt:
        print("\n! ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n! í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\n=== í¬ë¡¤ëŸ¬ ì¢…ë£Œ ===")


if __name__ == "__main__":
    from pathlib import Path
    main()
