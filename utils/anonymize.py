import re
from typing import Dict, List, Tuple, Any
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline, BertTokenizerFast, BertForTokenClassification

class PIIProcessor:
    """KoELECTRA NER + kor-naver-ner-nameì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ PII ë§ˆìŠ¤í‚¹ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        """PII í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        self.koelectra_model = None
        self.koelectra_tokenizer = None
        self.koelectra_pipeline = None
        
        self.name_model = None
        self.name_tokenizer = None
        self.name_pipeline = None
        
        self._load_models()
    
    def _load_models(self):
        """ë‘ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            print("ğŸ”„ KoELECTRA NER ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # KoELECTRA NER ëª¨ë¸ ë¡œë“œ
            ko_model_name = "Leo97/KoELECTRA-small-v3-modu-ner"
            self.koelectra_tokenizer = AutoTokenizer.from_pretrained(ko_model_name)
            self.koelectra_model = AutoModelForTokenClassification.from_pretrained(ko_model_name)
            self.koelectra_pipeline = pipeline("ner", model=self.koelectra_model, tokenizer=self.koelectra_tokenizer)
            
            print("âœ… KoELECTRA NER ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            
            print("ğŸ”„ kor-naver-ner-name ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # kor-naver-ner-name ëª¨ë¸ ë¡œë“œ
            name_model_name = "joon09/kor-naver-ner-name"
            self.name_tokenizer = BertTokenizerFast.from_pretrained(name_model_name)
            self.name_model = BertForTokenClassification.from_pretrained(name_model_name)
            self.name_pipeline = pipeline("ner", model=self.name_model, tokenizer=self.name_tokenizer)
            
            print("âœ… kor-naver-ner-name ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.koelectra_model = None
            self.name_model = None
    
    def mask_pii(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ PIIë¥¼ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤."""
        if not self.koelectra_pipeline or not self.name_pipeline:
            print("âš ï¸ ì¼ë¶€ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return text
        
        try:
            # 1ë‹¨ê³„: kor-naver-ner-nameìœ¼ë¡œ ì´ë¦„ ì¸ì‹
            name_entities = self.name_pipeline(text, grouped_entities=True, aggregation_strategy='average')
            
            # 2ë‹¨ê³„: KoELECTRAë¡œ ë‹¤ë¥¸ ê°œì²´ëª… ì¸ì‹
            other_entities = self.koelectra_pipeline(text)
            
            # 3ë‹¨ê³„: ë‘ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ë§ˆìŠ¤í‚¹ ì ìš©
            masked_text = self._apply_hybrid_masking(text, name_entities, other_entities)
            
            return masked_text
            
        except Exception as e:
            print(f"âŒ PII ë§ˆìŠ¤í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return text
    
    def _apply_hybrid_masking(self, text: str, name_entities: List[Dict], other_entities: List[Dict]) -> str:
        """ë‘ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ë§ˆìŠ¤í‚¹ì„ ì ìš©í•©ë‹ˆë‹¤."""
        if not name_entities and not other_entities:
            return text
        
        # ëª¨ë“  ê°œì²´ëª…ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ê²°í•©
        all_entities = []
        
        # ì´ë¦„ ê°œì²´ëª… ì²˜ë¦¬ (kor-naver-ner-name)
        for entity in name_entities:
            if entity['entity_group'] == 'PER':
                all_entities.append({
                    'start': entity['start'],
                    'end': entity['end'],
                    'word': entity['word'],
                    'entity': 'B-PS',  # KoELECTRA í˜•ì‹ìœ¼ë¡œ í†µì¼
                    'score': entity['score'],
                    'source': 'name_model'
                })
        
        # ë‹¤ë¥¸ ê°œì²´ëª… ì²˜ë¦¬ (KoELECTRA)
        for entity in other_entities:
            # ì´ë¦„ì´ ì•„ë‹Œ ê°œì²´ëª…ë§Œ ì¶”ê°€ (ì´ë¦„ì€ ì´ë¯¸ ì²˜ë¦¬ë¨)
            if not entity['entity'].startswith('B-PS') and not entity['entity'].startswith('I-PS'):
                all_entities.append({
                    'start': entity['start'],
                    'end': entity['end'],
                    'word': entity['word'],
                    'entity': entity['entity'],
                    'score': 1.0,  # KoELECTRAëŠ” ê¸°ë³¸ ì ìˆ˜
                    'source': 'koelectra'
                })
        
        # ê°œì²´ëª…ì„ ìœ„ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ë ìœ„ì¹˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
        sorted_entities = sorted(all_entities, key=lambda x: x['end'], reverse=True)
        
        masked_text = text
        
        for entity in sorted_entities:
            start = entity['start']
            end = entity['end']
            entity_text = entity['word']
            entity_type = entity['entity']
            score = entity['score']
            
            # ë§ˆìŠ¤í‚¹ íƒœê·¸ ê²°ì •
            mask_tag = self._get_mask_tag(entity_type, entity_text)
            
            if mask_tag:
                # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ê°œì²´ëª…ì„ ë§ˆìŠ¤í‚¹ íƒœê·¸ë¡œ êµì²´
                masked_text = masked_text[:start] + mask_tag + masked_text[end:]
        
        return masked_text
    
    def _get_mask_tag(self, entity_type: str, entity_text: str) -> str:
        """ê°œì²´ëª… íƒ€ì…ì— ë”°ë¥¸ ë§ˆìŠ¤í‚¹ íƒœê·¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # KoELECTRA NER íƒœê·¸ì…‹ì— ë”°ë¥¸ ë§ˆìŠ¤í‚¹
        tag_mapping = {
            'B-PS': '{ì´ë¦„}',      # ì¸ëª… (PERSON)
            'I-PS': '{ì´ë¦„}',      # ì¸ëª… (PERSON)
            'B-LC': '{ì£¼ì†Œ}',      # ì§€ì—­/ì¥ì†Œ (LOCATION)
            'I-LC': '{ì£¼ì†Œ}',      # ì§€ì—­/ì¥ì†Œ (LOCATION)
            'B-OG': '{ì†Œì†ì •ë³´}',   # ê¸°ê´€/ë‹¨ì²´ (ORGANIZATION)
            'I-OG': '{ì†Œì†ì •ë³´}',   # ê¸°ê´€/ë‹¨ì²´ (ORGANIZATION)
            'B-DT': '{ë‚ ì§œ}',      # ë‚ ì§œ/ê¸°ê°„ (DATE)
            'I-DT': '{ë‚ ì§œ}',      # ë‚ ì§œ/ê¸°ê°„ (DATE)
            'B-TI': '{ì‹œê°„}',      # ì‹œê°„ (TIME)
            'I-TI': '{ì‹œê°„}',      # ì‹œê°„ (TIME)
            'B-QT': '{ìˆ«ì}',      # ìˆ˜ëŸ‰ (QUANTITY)
            'I-QT': '{ìˆ«ì}',      # ìˆ˜ëŸ‰ (QUANTITY)
            'B-AF': '{ë¬¼ê±´}',      # ì¸ê³µë¬¼ (ARTIFACTS)
            'I-AF': '{ë¬¼ê±´}',      # ì¸ê³µë¬¼ (ARTIFACTS)
            'B-EV': '{ì‚¬ê±´}',      # ì‚¬ê±´/í–‰ì‚¬ (EVENT)
            'I-EV': '{ì‚¬ê±´}',      # ì‚¬ê±´/í–‰ì‚¬ (EVENT)
        }
        
        return tag_mapping.get(entity_type, None)
    
    def get_pii_info(self, text: str) -> Dict[str, List[str]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ PII ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.koelectra_pipeline or not self.name_pipeline:
            return {}
        
        try:
            # ì´ë¦„ ê°œì²´ëª… ì¶”ì¶œ (kor-naver-ner-name)
            name_entities = self.name_pipeline(text, grouped_entities=True, aggregation_strategy='average')
            
            # ë‹¤ë¥¸ ê°œì²´ëª… ì¶”ì¶œ (KoELECTRA)
            other_entities = self.koelectra_pipeline(text)
            
            # PII ì •ë³´ ìˆ˜ì§‘
            pii_info = {}
            
            # ì´ë¦„ ì •ë³´ ìˆ˜ì§‘
            for entity in name_entities:
                if entity['entity_group'] == 'PER':
                    if 'ì´ë¦„' not in pii_info:
                        pii_info['ì´ë¦„'] = []
                    pii_info['ì´ë¦„'].append(entity['word'])
            
            # ë‹¤ë¥¸ ê°œì²´ëª… ì •ë³´ ìˆ˜ì§‘
            for entity in other_entities:
                entity_type = entity['entity']
                entity_text = entity['word']
                
                # ì´ë¦„ì´ ì•„ë‹Œ ê°œì²´ëª…ë§Œ ì¶”ê°€
                if not entity_type.startswith('B-PS') and not entity_type.startswith('I-PS'):
                    # íƒœê·¸ íƒ€ì… ì •ë¦¬ (B-, I- ì œê±°)
                    clean_type = entity_type.replace('B-', '').replace('I-', '')
                    
                    # í•œê¸€ íƒœê·¸ëª…ìœ¼ë¡œ ë³€í™˜
                    korean_type = self._get_korean_type_name(clean_type)
                    
                    if korean_type not in pii_info:
                        pii_info[korean_type] = []
                    
                    if entity_text not in pii_info[korean_type]:
                        pii_info[korean_type].append(entity_text)
            
            return pii_info
            
        except Exception as e:
            print(f"âŒ PII ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def _get_korean_type_name(self, entity_type: str) -> str:
        """ì˜ë¬¸ íƒœê·¸ë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        type_mapping = {
            'PS': 'ì´ë¦„',
            'LC': 'ì£¼ì†Œ',
            'OG': 'ì†Œì†ì •ë³´',
            'DT': 'ë‚ ì§œ',
            'TI': 'ì‹œê°„',
            'QT': 'ìˆ«ì',
            'AF': 'ë¬¼ê±´',
            'EV': 'ì‚¬ê±´',
            'AM': 'ë™ë¬¼',
            'PT': 'ì‹ë¬¼',
            'MT': 'ì¬ë£Œ',
            'CV': 'ë¬¸ëª…',
            'FD': 'í•™ë¬¸',
            'TR': 'ì´ë¡ ',
            'TM': 'ìš©ì–´'
        }
        
        return type_mapping.get(entity_type, entity_type)


def anonymize_messages(data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¯¼ê°ì •ë³´ë¥¼ ìµëª…í™”í•©ë‹ˆë‹¤.
    
    Args:
        data (List[Dict[str, Any]]): ë©”ì‹œì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        List[Dict[str, Any]]: ìµëª…í™”ëœ ë©”ì‹œì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ”’ ìµëª…í™” ì²˜ë¦¬ ì¤‘...")
    
    # PII í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    try:
        pii_processor = PIIProcessor()
        print("âœ… PII í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ PII í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("   ì›ë³¸ ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return data
    
    anonymized_data = []
    for item in data:
        anonymized_item = item.copy()
        if 'message' in anonymized_item:
            try:
                anonymized_item['message'] = pii_processor.mask_pii(anonymized_item['message'])
            except Exception as e:
                print(f"âš ï¸ ë©”ì‹œì§€ ìµëª…í™” ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë©”ì‹œì§€ ìœ ì§€
                pass
        anonymized_data.append(anonymized_item)
    
    print(f"âœ… ìµëª…í™” ì™„ë£Œ: {len(data)}ê°œ ë©”ì‹œì§€")
    return anonymized_data
